{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24028dce",
   "metadata": {},
   "source": [
    "Goal: Load a MEGNet model from .pth, cut off layers after the first output MLP layer, then run inference on the dataset. Save the vector at the output of the MLP layer, with filename associated with the MP ID.\n",
    "\n",
    "Unlike MEGvect, MEGvect_e will output vector representations which had electronic properties included in the graph representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a7a7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import ast\n",
    "\n",
    "##torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader, Dataset, Data, InMemoryDataset\n",
    "from torch_geometric.utils import dense_to_sparse, degree, add_self_loops\n",
    "from torch_geometric.nn.models import meta\n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "import pymatgen as pmg\n",
    "from matdeeplearn.models.megnet import MEGNet\n",
    "from matdeeplearn.training.training import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_PATH = 'matdeeplearn/MEGNet_e_allmats.pth'\n",
    "MDL_CONFIG_PATH = 'matdeeplearn/MEGNet_e_allmats_settings.txt'\n",
    "OUT_DIR = 'mdl_data/representations_e'\n",
    "\n",
    "data_path = 'mdl_data/BGML_data/BGML_train/'\n",
    "processed_path = 'processed'\n",
    "\n",
    "target_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9328da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureDataset(InMemoryDataset):\n",
    "    def __init__(self, data_path, processed_path=\"processed\", transform=None, pre_transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.processed_path = processed_path\n",
    "        super(StructureDataset, self).__init__(data_path, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return os.path.join(self.data_path, self.processed_path)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        file_names = [\"data.pt\"]\n",
    "        return file_names\n",
    "\n",
    "class GetY(object):\n",
    "    def __init__(self, index=0):\n",
    "        self.index = index\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        if self.index != -1:\n",
    "            data.y = data.y[0][self.index]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "602969fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = GetY(index=target_index)\n",
    "if os.path.exists(os.path.join(data_path, processed_path, \"data.pt\")) == True:\n",
    "    dataset = StructureDataset(\n",
    "        data_path,\n",
    "        processed_path,\n",
    "        transforms,\n",
    "    )\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "data_structure_ids = [x.structure_id[0][0] for x in dataset]\n",
    "df_data_ids = pd.DataFrame(data_structure_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d0f66ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEGNet(\n",
       "  (pre_lin_list): ModuleList(\n",
       "    (0): Linear(in_features=40, out_features=100, bias=True)\n",
       "  )\n",
       "  (e_embed_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (1-3): 3 x Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (x_embed_list): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (u_embed_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=150, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (1-3): 3 x Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (conv_list): ModuleList(\n",
       "    (0-3): 4 x MetaLayer(\n",
       "      edge_model=Megnet_EdgeModel(\n",
       "      (edge_mlp): ModuleList(\n",
       "        (0): Linear(in_features=400, out_features=100, bias=True)\n",
       "        (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "      )\n",
       "      (bn_list): ModuleList(\n",
       "        (0-1): 2 x BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    ),\n",
       "      node_model=Megnet_NodeModel(\n",
       "      (node_mlp): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "        (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "      )\n",
       "      (bn_list): ModuleList(\n",
       "        (0-1): 2 x BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    ),\n",
       "      global_model=Megnet_GlobalModel(\n",
       "      (global_mlp): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=100, bias=True)\n",
       "        (1): Linear(in_features=100, out_features=100, bias=True)\n",
       "      )\n",
       "      (bn_list): ModuleList(\n",
       "        (0-1): 2 x BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    )\n",
       "  )\n",
       "  (bn_list): ModuleList()\n",
       "  (post_lin_list): ModuleList(\n",
       "    (0-2): 3 x Identity()\n",
       "  )\n",
       "  (lin_out): Identity()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in MEGNet_e config (txt)\n",
    "with open(MDL_CONFIG_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "    config = ast.literal_eval(data)\n",
    "c = config['Models']\n",
    "\n",
    "# Make the MEGNet\n",
    "device = 'cuda'\n",
    "model = MEGNet(dataset, c['dim1'], c['dim2'], c['dim3'], c['pre_fc_count'],\n",
    "               c['gc_count'], c['gc_fc_count'], c['post_fc_count'],\n",
    "               c['pool'], c['pool_order'], c['batch_norm'], c['batch_track_stats'],\n",
    "               c['act'], c['dropout_rate']\n",
    "              ).to(device)\n",
    "# Reload parameters\n",
    "d = torch.load(MODEL_PATH)\n",
    "model.load_state_dict(d['model_state_dict'])\n",
    "\n",
    "# Trim off the linear layers (may need to change this if the MEGNet was made differently)\n",
    "model.post_lin_list[0] = nn.Identity()\n",
    "model.post_lin_list[1] = nn.Identity()\n",
    "model.post_lin_list[2] = nn.Identity()\n",
    "model.lin_out = nn.Identity()\n",
    "\n",
    "# output are 300D vectors\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb937271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 290/290 [00:43<00:00,  6.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on some data\n",
    "model.eval()\n",
    "\n",
    "for data in tqdm(loader):\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "    # save the representation vectors\n",
    "    for i, name in enumerate(data.structure_id):\n",
    "        fn = os.path.join(OUT_DIR, name[0][0] + '_repr.pt') \n",
    "        torch.save(out[i], fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f497c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
